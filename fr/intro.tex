\chapter{Introduction}
\label{chap:intro}

\section{A propros de la gestion source}

La gestion de source est un processus permettant de gérer différentes
version de la même information. Dans sa forme la plus simple, c'est
quelquechose que tout le monde fait manuellement : quand vous modifiez
un fichier, vous le sauvegarder sous un nouveau nom contenant un numéro,
à chaque fois plus grand la précédente version.

Ce genre de gestion de version manuel est cependant sujette facilement
à des erreurs, ainsi, depuis longtemps, des logiciels existent pour
adresser cette problématique. Les premiers outils de gestion de source
étaient destinés à aider un seul utilisateur, à automatiser la gestion
des versions d'un seulf fichier. Dans les dernières décades, cette cilble 
a largement était agrandie, ils gèrent désormais de multiple fichiers, et
aident un grand nombre de personnes à travailler ensemble. Le outils les
plus modernes n'ont aucune difficultés à gérer plusieurs milliers de 
personnes travaillant ensemble sur des projets regroupant plusieurs 
centaines de milliers de fichiers.

\subsection{Pourquoi utiliser un gestionnaire de source ?}

Il y a de nombreuse raisons pour que vous ou votre équipe souhaitiez
utiliser un outil automatisant la gestion de version pour votre projet.
\begin{itemize}
\item L'outil se chargera de suivre l'évolution de votre projet, sans
que vous ayez à le faire. Pour chaque modification, vous aurez à votre
disposition un journal indiquant \emph{qui} a faient quoi, \emph{pourquoi}
ils l'ont fait, \emph{quand} ils l'ont fait, et \emph{ce} qu'ils ont
modifiés.
\item Quand vous travaillez avec d'autres personnes, les logiciels de 
gestion de source facilite le travail collaboratif. Par exemple, quand
plusieurs personnes font, plus ou moins simultannéement, des modifications
incompatibles, le logiciel vous aidera à identifier et résoudre les conflits.
\item L'outil vous aidera à réparer vos erreurs. Si vous effectuez un changement
qui se révèlera être une erreur, vous pourrez revenir fiablement à une version
antérieur d'une fichier ou même d'un ensemble de fichier. En fait, un outil de
gestion de source \emph{vraiment} efficace vous permettra d'identifier à quel
moment le problème est apparu (voir la section~\ref{sec:undo:bisect} pour plus
de détails).
\item L'outil vous permettra aussi de travailler sur plusieurs versions différentes
de votre projet et à gérer l'écart entre chaque.
\end{itemize}
La plupart de ces raisons ont autant d'importances---du moins en théorie--- que
vous travailliez sur un projet pour vous, ou avec une centaine d'autres
personnes.

Une question fondamental à propos des outils de gestion de source, qu'il s'agisse
du projet d'une personne ou d'une grande équipe, est quelles sont ses  
\emph{avantages} par rapport à ses \emph{coût}. Un outil qui est difficile à 
utiliser ou à comprendre exigera un effort d'adoption.

Un projet de cinq milles personnnes s'effondrera très certainement de lui même
sans aucun processus et outil de gestion de source. Dans ce cas, le coût 
d'utilisation d'un logiciel de gestion de source est dérisoire, puisque 
\emph{sans}, l'échec est presque garanti.

D'un autre coté, un ``rapide hack'' d'une personnne peut sembler un contexte
bien pauvre pour utiliser un outil de gestion de source, car, bien évidement
le coût d'utilisation dépasse le coût total du projet. N'est ce pas ?

Mercurial supporte ces \emph{deux} échelles de travail. Vous pouvez apprendre
les bases en juste quelques minutes, et, grâce à sa performance, vous pouvez
l'utiliser avec facilité sur le plus petit des projets. Cette simplicité 
signifie que vous n'avez pas de concepts obscures ou de séquence de commandes
défiant l'imagination, complètement décorrelé de \emph{ce que vous êtes 
vraiment entrain de faire}. En même temps, ces mêmes performances et sa 
nature ``peer-to-peer'' vous permet d'augmenter, sans difficulté, son 
utilisation à de très grand projet.

Aucun outil de gestion de source ne peut sauver un projet mal mené, mais un
bon outil peut faire une grande différence dans la fluidité avec lequel 
vous pourrez travailler avec.

\subsection{Les multiples noms de la gestion de source}

La gestion de source est un domaine divers, tellement qu'il n'existe pas
une seul nom ou acronyme pour le désigner. Voilà quelqu'uns des noms ou 
acronymes que vous rencontrerez le plus souvent:
\begin{itemize}
\item \textit{Revision control (RCS)} ;
\item Software configuration management (SCM), ou \textit{configuration management} ;
\item \textit{Source code management} ;
\item \textit{Source code control}, ou \textit{source control} ;
\item \textit{Version control (VCS)}.
\end{itemize}

\notebox {
Note du traducteur : J'ai conservé la liste des noms en anglais pour des raisons de commodité (ils sont plus ``googelable''). J'ai choisi de conserver le terme ``gestion de sources'' comme traduction unique dans l'ensemble du document.

En outre, j'ai opté pour conserver l'ensemble des opérations de Mercurial (commit, push, pull,...) en anglais, là aussi pour faciliter la lecture d'autres documents en anglais, et 
aussi son utilisation.
}

Certains personnes prétendent que ces termes ont en fait des sens
différents mais en pratique ils se recouvrent tellement qu'il n'y a pas
réellement de manière pertinente de les distinguer.

\section{Une courte histoire de la gestion de source}

Le plus célèbre des anciens outils de gestion de source est \textit{SCCS (Source
Code Control System)}, que Marc Rochkind conçu dans les laboratoire de recherche de Bell 
(\textit{Bell Labs}), dans le début des années 70. \textit{SCCS} ne fonctionner que sur des fichiers individuels, et demandait à personne travaillant sur le projet d'avoir un accès à un répertoire de travail commun, sur un unique système.
Seulement une personne pouvait modifier un fichier au même moment, ce fonctionnement était assuré par l'utilisation de verrou (``lock''). Il était courant que des personnes ne vérouille
des fichiers, et plus tard, oublie de le dévérouiller; empêchant  n'importe qui d'autre de 
travailler sur ces fichiers sans l'aide de l'administrateur...

Walter Tichy a développé une alternative libre à \textit{SCCS} au début des années 80, qu'il
nomma \textit{RSC (Revison Control System)}.  Comme \textit{SCCS}, \textit{RCS}
demander aux développeurs de travailler sur le même répertoire partagé, et de vérouiller les
fichiers pour se prémunir de tout conflit issue de modifications concurrentes.

Un peu plus tard dans les années 1980, Dick Grune utilisa \textit{RCS} comme une brique de base pour un ensemble de scripts \textit{shell} qu'il intitula cmt, avant de la renommer en \textit{CVS (Concurrent Versions System)}.  La grande innovation de CVS était que les développeurs pouvaient travailler simultanéement and indépendament dans leur propre espace de travail. Ces espaces de travail privés assuraient que les développeurs ne se marche mutuellement sur les pieds, comme c'était souvent le cas avec RCS et SCCS. Chaque développeur disposait donc de sa copie de tout les fichiers du projet, et ils pouvaient donc librement les modifier. Ils devaient néanmoins effectuer la ``fusion'' (\textit{``merge''}) de leur fichiers, avant d'effectuer le ``commit'' de leur modification sur le dépôt central.

Brian Berliner repris les scripts de Grune's et les réécris en~C, qu'il publia en 1989. Depuis, ce code a été modifié jusqu'à devenir la version moderne de CVS. CVS a acquis ainsi la capacité de fonctionner en réseau, le transformant son architecture en client/serveur. L'architecture de CVS est centralisée, seul le serveur a une copie de l'historique du projet. L'espace de travail client ne contient qu'une copie de la dernière version du projet, et quelques métadonnées pour indiquer où le serveur se trouve. CVS a été un grand succès, aujourd'hui c'est probablement l'outil de gestion de contrôle le plus utilisé au monde. 

Au début des années 1990, Sun Microsystmes développa un premier outil de gestion de source distribué, nommé TeamWare. Un espace de travail TeamWare contient une copie complète de l'historique du projet. TeamWare n'a pas de notion de dépot central. (CVS utilisé RCS pour le stockage de l'historique, TeamWare utilisé SCCS).

Alors que les années 1990 avancé, les utilisateurs ont pris conscience d'un certain nombre de problème avec CVS. Il enregistrait simultanéement des modifications sur différents fichier individuellement, au lieu de les regrouper dans une seule opération cohérente et atomique. Il ne gère pas bien sa hiérarchie de fichier, il est donc assez aisé de créer le chaos en renommant les fichiers et les répertoires. Pire encore, son code source est difficile à lire et à maintenir, ce qui agrandit largement le ``niveau de souffrance'' associé à la réparation de ces problèmes d'architecture de manière prohibitive. 


En 2001, Jim Blandy et Karl Fogel, deux développeurs qui avaient travaillé sur CVS, initialisèrent un projet pour le remplacer par un outil qui aurait une meilleur architecture et un code plus propre. Le résultat, Subversion, ne quitte pas le modèle centralisé et client/server de CVS, mais ajoute les opérations de ``commit'' atomique sur de multiples fichier, une meilleur gestion des espaces de noms, et d'autres fonctionnalités qui en font un meilleur outil que CVS. Depuis sa première publication, il est rapidement devenu très populaire.

Plus ou moins de manière simultanné, Graydon Hoare a commencé sur l'ambitieux système de gestion distribué Monotone. Bien que Monotone corrige plusieurs défaut de CVS's tout en offrant une architecture ``peer-to-peer'', il va aussi plus loin que la plupart des outils de révision de manière assez innovante. Il utilise des ``hash'' cryptographique comme identifiant, et il a notion complète de ``confiance'' du code issues de différentes sources.

Mercurial est né en 2005. Bien que très influencé par Monotone, Mercurial se concentre sur la facilité d'utilisation, les performances et la capacité à monter en charge pour de très grand projets.

\section{Tendances de la gestion de source}

Il y a eu une tendance évidente dans le développement et l'utilisation d'outil de gestion de source depuis les quatre dernière décades, au fur et à mesure que les utilisateurs se sont habitués à leur outils et se sont sentis contraint par leur limitations.

La première génération commença simplement par gérer un fichier unique sur un ordinateur individuel. Cependant, même si ces outils présentè-rent une grande avancée par rapport à la gestion manuel des versions, leur modèle de vérouillage et leur utilisation limité à un seul ordinateur rendaient leur utilisation possible uniquement dans une très petite équipe. 

La seconde génération a assoupli ces contraintes en adoptant une architecture réseau et centralisé, permettant de gérer plusieurs projets entiers en même temps. Alors que les projets grandirent en taille, ils rencontrèrent de nouveau problèmes. Avec les clients discutant régulièrement avec le serveurs, la monte en charge devint un réellement problème sur les gros projets. Une connexion réseau peu fiable pouvant empêcher simplement les utilisateurs distant de discuter avec le serveur. Alors que les projets \textit{Open Source} commencèrent à mettre en place des accès en lecture seule disponible anonymement, les utilisateurs sans les privilèges de ``commit'' réalisèrent qu'ils ne pouvaient pas utiliser les outils pour collaboraient naturellement avec le projet, comme ils ne pouvaient pas non plus enregistrer leurs modifications.

La génération actuelle des outils de gestion de source est ``peer-to-peer'' par nature. Tout ces systèmes ont abandonné la dépendance à un serveur central, et ont permis à leur utilisateur de distribué les données de leur gestion de source à qui en a besoin. La collaboration à travers Internet a transformée la contrainte technologique à une simple question de choix et de consencus. Les outils moderne peuvent maintenant fonctionner en mode déconnecté sans limite et de manière autonome, la connexion au réseau n'étant nécessaire que pour synchroniser les modifications avec les autres dépots.

\section{Quelques avantages des gestionnaire de source distribué}

Même si les gestionnaire de source distribué sont depuis plusieurs années
assez robuste et aussi utilisable que leur prédécésseurs, les utilisateurs
d'autres outils n'ont pas encore étaient sensibilisé. Les gestionnaires
de sources distribué se distingue particulièrement de leurs équivalents
centralisé de nombreuse manière.

Pour un développeur individuel, ils restent beaucoup plus rapide que les
outils centralisés. Cela pour une raison simple: un outil centralisé doit
toujours discuter à travers le réseau pour la plupart des opérations, car
presque toutes les métadonnées sont stockées sur la seule copie du serveur
central. Un outil distribué stocke toute ses métadonnées localement. À tâche
égale, effectuer un échange avec le réseau ajoute un délai aux outils 
centralisés. Ne sous estimez pas la valeur d'un outil rapide: vous allez
passer beaucoup de temps à interagir avec un logiciel de gestion de sources.

Les outils distribué sont complètement indépendant des aléas de votre serveur,
encore une fois car ils répliquent les métadonnées à tellement d'endoit. Si
votre serveur central prend feu, vous avez intérêt à ce que les média de 
sauvegarde soient fiable, et que votre dernier ``backup'' soit récent et
fonctionne sans problème. Avec un outil distribué, vous avez autant de 
``backup'' que de contributeurs.

En outre, la fiabilité de votre réseau affectera beaucoup moins les
outils distribué. Vous ne pouvez même pas utiliser un outil centralisé
sans connexion réseau, à l'exception de quelques commandes, très limités. 
Avec un outil distribué, si vous connexion réseau tombe pendant que vous
travaillez, vous pouvez ne même pas vous en rendre compte. La seule chose
que vous ne serez pas capable de faire sera de communiquer avec des dépôts
distants, opération somme toute assez rare par comparaison aux opérations
locales. Si vous avez une (TODO:far-flung???) équipe de collaborateurs, 
ceci peut être significatif.

\subsection{Avantages pour les projets \textit{Open Source}}

Si vous prenez goût à un projet \textit{Open Source} et que vous
décidez de commencer à toucher à son code, et que le projet utilise
un gestionnaire de source distribué, vous êtes immédiatement un "pair"
avec les personnes formant le ``coeur'' du projet. Si ils publient
leurs dépôts, vous pouvez immédiatement copier leurs historiques de
projet, faire des modifications, enregistrer votre travail en utilisant
les même outils qu'eux. Par comparaison, avec un outil centralisé, vous
devez utiliser un logiciel en mode ``lecture seule'' à moins que 
quelqu'un ne vous donne les privilèges de ``commit'' sur le serveur
central. Avant ça, vous ne serez pas capable d'enregistrer vos 
modifications, et vos propres modifications risqueront de se 
corrompre chaque fois que vous essayerez de mettre à jour à votre
espace de travail avec le serveur central.

\subsubsection{Le non-problème du \textit{fork}}

Il a été souvent suggeré que les gestionnaires de source distribués
posent un risque pour les projets \textit{Open Source} car ils 
facilitent grandement la création de ``fork''\footnote{NdT:Création 
d'une version alternative du logiciel}. %%% TODO: Link to Wikipedia
Un ``fork'' apparait quand il y des divergences d'opinion ou d'attitude
au sein d'un groupe de développeurs qui aboutit à la décision de ne 
plus travail ensemble. Chacun parti s'empare d'une copie plus ou moins
complète du code source du projet et continue dans sa propre direction.

Parfois ces différents partis décide de se réconcilier. Avec un 
serveur central, l'aspect \emph{technique} de cette réconciliation
est un processus douloureux, et essentiellement manuel. Vous devez
décider quelle modification est ``la gagnante'', et replacer, par un
moyen ou un autre, les modifications de l'autre équipe dans l'arboresence
du projet. Ceci implique généralement la perte d'une partie l'historique 
d'un des partie, ou même des deux.

Ce que les outils distribués permettent à ce sujet est probablement
la \emph{meilleur} façon de développer un projet. Chaque modification
que vous effectué est potentiellement un ``fork''. La grande force de 
cette approche est que les gestionnaire de source distribué doit être
vraiment très efficase pour \emph{fusionner}\footnote{NdT:j'ai choisi de
traduire ici \textit{merging} par ``fusionner'' pour des raisons de clarté}
des ``forks'', car les ``forks'', dans ce contexte, arrivent tout le
temps.

Si chaque altération que n'importe qui effectue, à tout moment, est vu
comme un ``fork'' à fusionner, alors ce que le monde de l'\textit{Open 
Source} voit comme un ``fork'' devient \emph{uniquement} une problématique 
social. En fait, les outils de gestion de source distribué \emph{réduisent} 
les chances de ``fork'':
\begin{itemize}
\item Ils éliminent la distinction social qu'imposent les outils centralisés
	entre les membres du projets (ce qui ont accès au ``comit'') et ceux de l'
	extérieur (ce qui ne l'ont pas).
\item Ils rendent plus facile la réconciliation après un ``fork'' social, car
	tout ce qu'elle implique est juste une simple fusion.
\end{itemize}

Certaines personnes font de la résistance envers les gestionnaires de source
distribués parce qu'ils veulent garder un contrôle ferme de leur projet, et
ils pensent que les outils centralisés leur fournissent ce contrôle. Néanmoins,
si c'est votre cas, sachez que si vous publier votre dépôt CVS ou Subversion
de manière publique, il existe une quantité d'outils disponibles pour récupérer
entièrement votre projet et son historique (quoique lentement) et le récréer 
ailleurs, sans votre contrôle. En fait, votre contrôle sur votre projet est 
illusoire, vous ne faites qu'interdire à vos collaborateurs de travailler
de manière fluide, en disposant d'un miroir ou d'un ``fork'' de votre
historique.
%%%TODO: Fussy, those last sentences are not really well translated:
%However, if you're of this belief, and you publish your CVS or Subversion 
%repositories publically, there are plenty of tools available that can pull 
%out your entire project's history (albeit slowly) and recreate it somewhere 
%that you don't control.  So while your control in this case is illusory, you are
%forgoing the ability to fluidly collaborate with whatever people feel
%compelled to mirror and fork your history.

\subsection{Avantages pour les projets commerciaux}

Beaucoup de projets commerciaux sont réalisé par des équipes éparpillées
à travers le globe. Les contributeurs qui sont loin du serveur central
devront subir des commandes lentes et même parfois peu fiable. Les 
solutions propriétaires gestion de source, tentent de palier ce problème 
avec des réplications de site distant qui sont à la fois coûteuses à mettre
en place et lourdes à administrer. A un système distribué ne souffre pas
de ce genre de problèmes. En outre, il est très aisé de mettre en place
plusieurs serveurs de références, disont un par site, de manière à ce qu'il
n'y est pas de communication redondante entre les dépôts, sur une connexion
longue distance souvent onéreuse.

Les systèmes de gestion de source supportent généralement assez mal la 
monté en charge. Ce n'est pas rare pour un gestionnaire de source centralisé 
pourtant onéreux de s'effondrer sous la charge combinée de juste une douzaine 
d'utilisateurs concurrents. Une fois encore, la réponse à cette problématique 
est généralement encore la mise en place d'un ensemble complexe de serveurs
synchronisé par un mécanisme de réplication. Dans le cas d'un gestionnaire
de source distribué, la charge du serveur central--- si vous avez un--- est
plusieurs fois inférieur (car toutes les données sont déjà répliqués ailleurs),
un simple server, pas très cher, peut gérer les besoins d'une plus grande
équipe, et la réplication pour balancer la charge devient simplement le
travail d'un simple script.

Si vous avez des employés sur le terrain, entrain de chercher à résoudre sur
le site d'un client, ils bénéficieront aussi d'un gestionnaire de source
distribués. Cet outil leur permettra de générer des versions personnalisées,
d'essayer différentes solutions, en les isolant aisément les une des autres,
et de recherche efficasement à travers l'historique des sources, la cause
des bugs ou des régression, tout ceci sans avoir besoin de la moindre 
connexion au réseau de votre compagnie.

\section{Pourquoi choisir Mercurial?}

Mercurial a plusieurs caractéristiques qui en font un choix particulièrement
pertinent pour la gestion de source:
\begin{itemize}
	\item Il est facile à apprendre et à utiliser ;It is easy to learn and use.
	\item il est léger et performant ;
	\item il monte facilement en charge ; 
	\item il est facile à personnaliser ;
\end{itemize}

Si vous êtes déjà familier d'un outil de gestion de source, vous serez
capable de l'utiliser en moins de 5 minutes. Sinon, ça ne sera pas beaucoup
plus long\footnote{NdT: Pour appuyer le propos de l'auteur, je signale que 
j'utilise Mercurial comme outil d'initiation à la gestion de contrôle dans
des travaux pratique à l'ESME Sudria (\url{http://www.esme.fr}) et que les
élèves le prennent en main sans difficulté majeur malgré l'approche distribuée.}. 
Les commandes utilisées par Mercurial, comme ses fonctionnalités, sont 
généralement uniformes et cohérentes, et vous pouvez donc ainsi garder en tête 
simplement quelques règles générales, plutôt qu'un lot complexe d'exceptions.

Sur un petit projet, vous pouvez commencer à travailler avec Mercurial en
quelques instants. Ajouter des modifications ou des branches, transférer 
ces modifications (localement ou via le réseau), et les opérations 
d'historique ou de statut sont aussi très rapide. Mercurial reste hors de 
votre chemin grâce à sa simplicité d'utilisation et sa rapidité d'exécution.

L'utilité de Mercurial ne se limite pas à des petits projets: il est 
aussi utilisé par des projets ayant des centaines ou même des milliers
de contributeurs, avec plusieurs dizaines de milliers de fichiers, et des
centaines de méga de code source.

Voici une liste non exhaustive des projets complexe ou critique utilisant 
mercurial :
%TODO
% For both spanish and english version, add the following examples:
\begin{itemize}
	\item Firefox ;
	\item OpenSolaris ;
	\item OpenJDK (utilisant en outre l'extension ``forest'' pour gérer
	ses sous modules);
\end{itemize}
% TODO: Also add appropriate link.

Si les fonctionnalités coeur de Mercurial ne sont pas suffisantes pour vous, 
il est très aisé de construire dessus. Mercurial est adapté à l'utilisation
au sein de script, et son implémentation interne en python, propre et claire,
rend encore plus facile l'ajout de fonctionnalité sous forme d'extension. Il
en existe déjà un certains nombres de très populaires et très utiles, 
dont le périmètre va de la recherche de bugs à l'amélioration des performances.

\section{Mercurial compared with other tools}

Before you read on, please understand that this section necessarily
reflects my own experiences, interests, and (dare I say it) biases.  I
have used every one of the revision control tools listed below, in
most cases for several years at a time.


\subsection{Subversion}

Subversion is a popular revision control tool, developed to replace
CVS.  It has a centralised client/server architecture.

Subversion and Mercurial have similarly named commands for performing
the same operations, so if you're familiar with one, it is easy to
learn to use the other.  Both tools are portable to all popular
operating systems.

Prior to version 1.5, Subversion had no useful support for merges.
At the time of writing, its merge tracking capability is new, and known to be
\href{http://svnbook.red-bean.com/nightly/en/svn.branchmerge.advanced.html#svn.branchmerge.advanced.finalword}{complicated
  and buggy}.

Mercurial has a substantial performance advantage over Subversion on
every revision control operation I have benchmarked.  I have measured
its advantage as ranging from a factor of two to a factor of six when
compared with Subversion~1.4.3's \emph{ra\_local} file store, which is
the fastest access method available.  In more realistic deployments
involving a network-based store, Subversion will be at a substantially
larger disadvantage.  Because many Subversion commands must talk to
the server and Subversion does not have useful replication facilities,
server capacity and network bandwidth become bottlenecks for modestly
large projects.

Additionally, Subversion incurs substantial storage overhead to avoid
network transactions for a few common operations, such as finding
modified files (\texttt{status}) and displaying modifications against
the current revision (\texttt{diff}).  As a result, a Subversion
working copy is often the same size as, or larger than, a Mercurial
repository and working directory, even though the Mercurial repository
contains a complete history of the project.

Subversion is widely supported by third party tools.  Mercurial
currently lags considerably in this area.  This gap is closing,
however, and indeed some of Mercurial's GUI tools now outshine their
Subversion equivalents.  Like Mercurial, Subversion has an excellent
user manual.

Because Subversion doesn't store revision history on the client, it is
well suited to managing projects that deal with lots of large, opaque
binary files.  If you check in fifty revisions to an incompressible
10MB file, Subversion's client-side space usage stays constant The
space used by any distributed SCM will grow rapidly in proportion to
the number of revisions, because the differences between each revision
are large.

In addition, it's often difficult or, more usually, impossible to
merge different versions of a binary file.  Subversion's ability to
let a user lock a file, so that they temporarily have the exclusive
right to commit changes to it, can be a significant advantage to a
project where binary files are widely used.

Mercurial can import revision history from a Subversion repository.
It can also export revision history to a Subversion repository.  This
makes it easy to ``test the waters'' and use Mercurial and Subversion
in parallel before deciding to switch.  History conversion is
incremental, so you can perform an initial conversion, then small
additional conversions afterwards to bring in new changes.


\subsection{Git}

Git is a distributed revision control tool that was developed for
managing the Linux kernel source tree.  Like Mercurial, its early
design was somewhat influenced by Monotone.

Git has a very large command set, with version~1.5.0 providing~139
individual commands.  It has something of a reputation for being
difficult to learn.  Compared to Git, Mercurial has a strong focus on
simplicity.

In terms of performance, Git is extremely fast.  In several cases, it
is faster than Mercurial, at least on Linux, while Mercurial performs
better on other operations.  However, on Windows, the performance and
general level of support that Git provides is, at the time of writing,
far behind that of Mercurial.

While a Mercurial repository needs no maintenance, a Git repository
requires frequent manual ``repacks'' of its metadata.  Without these,
performance degrades, while space usage grows rapidly.  A server that
contains many Git repositories that are not rigorously and frequently
repacked will become heavily disk-bound during backups, and there have
been instances of daily backups taking far longer than~24 hours as a
result.  A freshly packed Git repository is slightly smaller than a
Mercurial repository, but an unpacked repository is several orders of
magnitude larger.

The core of Git is written in C.  Many Git commands are implemented as
shell or Perl scripts, and the quality of these scripts varies widely.
I have encountered several instances where scripts charged along
blindly in the presence of errors that should have been fatal.

Mercurial can import revision history from a Git repository.


\subsection{CVS}

CVS is probably the most widely used revision control tool in the
world.  Due to its age and internal untidiness, it has been only
lightly maintained for many years.

It has a centralised client/server architecture.  It does not group
related file changes into atomic commits, making it easy for people to
``break the build'': one person can successfully commit part of a
change and then be blocked by the need for a merge, causing other
people to see only a portion of the work they intended to do.  This
also affects how you work with project history.  If you want to see
all of the modifications someone made as part of a task, you will need
to manually inspect the descriptions and timestamps of the changes
made to each file involved (if you even know what those files were).

CVS has a muddled notion of tags and branches that I will not attempt
to even describe.  It does not support renaming of files or
directories well, making it easy to corrupt a repository.  It has
almost no internal consistency checking capabilities, so it is usually
not even possible to tell whether or how a repository is corrupt.  I
would not recommend CVS for any project, existing or new.

Mercurial can import CVS revision history.  However, there are a few
caveats that apply; these are true of every other revision control
tool's CVS importer, too.  Due to CVS's lack of atomic changes and
unversioned filesystem hierarchy, it is not possible to reconstruct
CVS history completely accurately; some guesswork is involved, and
renames will usually not show up.  Because a lot of advanced CVS
administration has to be done by hand and is hence error-prone, it's
common for CVS importers to run into multiple problems with corrupted
repositories (completely bogus revision timestamps and files that have
remained locked for over a decade are just two of the less interesting
problems I can recall from personal experience).

Mercurial can import revision history from a CVS repository.


\subsection{Commercial tools}

Perforce has a centralised client/server architecture, with no
client-side caching of any data.  Unlike modern revision control
tools, Perforce requires that a user run a command to inform the
server about every file they intend to edit.

The performance of Perforce is quite good for small teams, but it
falls off rapidly as the number of users grows beyond a few dozen.
Modestly large Perforce installations require the deployment of
proxies to cope with the load their users generate.


\subsection{Choosing a revision control tool}

With the exception of CVS, all of the tools listed above have unique
strengths that suit them to particular styles of work.  There is no
single revision control tool that is best in all situations.

As an example, Subversion is a good choice for working with frequently
edited binary files, due to its centralised nature and support for
file locking.

I personally find Mercurial's properties of simplicity, performance,
and good merge support to be a compelling combination that has served
me well for several years.


\section{Switching from another tool to Mercurial}

Mercurial is bundled with an extension named \hgext{convert}, which
can incrementally import revision history from several other revision
control tools.  By ``incremental'', I mean that you can convert all of
a project's history to date in one go, then rerun the conversion later
to obtain new changes that happened after the initial conversion.

The revision control tools supported by \hgext{convert} are as
follows:
\begin{itemize}
\item Subversion
\item CVS
\item Git
\item Darcs
\end{itemize}

In addition, \hgext{convert} can export changes from Mercurial to
Subversion.  This makes it possible to try Subversion and Mercurial in
parallel before committing to a switchover, without risking the loss
of any work.

The \hgxcmd{conver}{convert} command is easy to use.  Simply point it
at the path or URL of the source repository, optionally give it the
name of the destination repository, and it will start working.  After
the initial conversion, just run the same command again to import new
changes.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "00book"
%%% End: 
